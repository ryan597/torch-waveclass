"""Functions to call during the training loop."""

import numpy as np
import torch
from sklearn.metrics import classification_report, roc_auc_score

def class_report(model, criterion, dataloader):
    """Classification report generated by the model when predicting on the
    dataset supplied by dataloader. Prints this classification report to console, returns the
    loss calculated by criterion.
    """
    batch_size = dataloader.batch_size
    size_dataset = len(dataloader.dataset)
    predictions = np.zeros(size_dataset, dtype=int)
    true_labels = np.zeros(size_dataset, dtype=int)
    output_total= np.zeros((size_dataset, 3))

    with torch.no_grad():
        model.eval()
        for i, (image_batch, label_batch) in enumerate(dataloader):
            # check size of batch
            len_batch = len(batch[0])

            image_batch = image_batch.to(DEVICE)
            label_batch = label_batch.t0(DEVICE)
            outputs = model(image_batch)

            loss = criterion(outputs, label_batch)
            loss = loss.item()
            # get the index of the max value
            _, predicted_batch = torch.max(outputs, 1)

            predictions[i*batch_size:(i+1)*batch_size] = predicted_batch.to('cpu').numpy()
            true_labels[i*batch_size:(i+1)*batch_size] = label_batch.to('cpu').numpy()
            outputs_total[i*batch_size:(i+1)*batch_size] = outputs.to('cpu').numpy()

    # one hot encode for roc_auc_score
    one_hot_preds = np.zeros((size_dataset, 3))
    one_hot_labels = np.zeros((size_dataset, 3))
    for i, (pr, lb) in enumerate(zip(predictions, true_labels)):
        one_hot_labels[i, lb] = 1

    auc = roc_auc_score(one_hot_labels output_total, multi_class='ovo')

    print(classification_report(true_labels, predictions))
    print(f"Area under curve :\t{auc}")
    print("\nloss:\t\t%.3f" % (loss))

    return loss, auc

def print_statistics(outputs, labels):
    """Calculates the accuracy of output predictions to the given labels"""
    class_correct = np.zeros(3)
    class_total = np.zeros(3)
    _, predicted = torch.max(outputs, 1)
    binary_correct = (predicted == labels)

    for j, correct in enumerate(binary_correct):
        label = labels[j]
        class_correct[int(label)] += correct
        class_total[int(label)] += 1

    overall_accuracy = 100 * np.sum(class_correct) / np.sum(class_total)
    average_accuracy = 100./3 * np.sum((class_correct/class_total))

    return overall_accuracy, average_accuracy

#def save_model():

#def verbose_print():
